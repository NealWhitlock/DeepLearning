{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Major Neural Network Architectures Challenge\n",
    "## *Data Science Unit 4 Sprint 3 Challenge*\n",
    "\n",
    "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
    "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
    "\n",
    "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime locally, on AWS SageMaker, on Colab or on a comparable environment. If something is running longer, double check your approach!\n",
    "\n",
    "## Challenge Objectives\n",
    "*You should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
    "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for object detection\n",
    "* <a href=\"#p3\">Part 3</a>: Describe a use case for an autoencoder\n",
    "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5UwGRnJOmD4"
   },
   "source": [
    "<a id=\"p1\"></a>\n",
    "## Part 1 - LSTMSs\n",
    "\n",
    "Use a LSTM to fit a multi-class classification model on Reuters news articles to distinguish topics of articles. The data is already encoded properly for use in a LSTM model. \n",
    "\n",
    "Your Tasks: \n",
    "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
    "- Report your overall score and accuracy\n",
    "\n",
    "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well as the LSTM code we used in class.\n",
    "\n",
    "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=723812,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLKqFh8DovaN",
    "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n",
      "Iran is encoded as 779 in the data\n",
      "London is encoded as 544 in the data\n",
      "Words are encoded as numbers in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Demo of encoding\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
    "print(f\"London is encoded as {word_index['london']} in the data\")\n",
    "print(\"Words are encoded as numbers in our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this line. You need the +1 for some reason. \n",
    "max_features = len(word_index.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QVSlFEAqWJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([1, 248, 409, 166, 265, 1537, 1662, 8, 24, 4, 1222, 2771, 7, 227, 236, 40, 85, 944, 10, 531, 176, 8, 4, 176, 1613, 24, 1662, 297, 5157, 6, 10, 103, 5, 231, 215, 8, 7, 2889, 6, 10, 1202, 69, 4, 1222, 329, 2771, 24, 944, 23, 944, 1662, 40, 2509, 1592, 907, 69, 4, 113, 997, 762, 2539, 7, 227, 236, 17, 12]),\n",
       "       list([1, 4665, 1183, 413, 381, 7, 1134, 1664, 62, 729, 7, 4, 121, 273, 93, 109, 28, 2115, 72, 11, 428, 4, 387, 989, 558, 3956, 8, 7, 25, 1213, 427, 1969, 223, 4, 213, 5, 387, 580, 8, 1145, 413, 62, 410, 451, 18, 428, 7, 4, 121, 6, 3106, 19, 11, 428, 9, 1283, 317, 65, 413, 138, 59, 12, 11, 428, 6, 6118, 63, 11, 4, 3956, 8, 3640, 1183, 413, 202, 251, 18, 428, 6, 546, 19, 11, 428, 9, 317, 65, 413, 7, 4, 1721, 427, 409, 7145, 138, 19, 19, 11, 428, 6, 3843, 70, 11, 4, 135, 5, 137, 317, 1833, 542, 9, 7145, 413, 138, 72, 47, 11, 428, 6, 19, 5106, 19, 16, 8, 17, 12])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - your code!\n",
    "print(X_train.shape)\n",
    "X_train[:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 train sequences\n",
      "2246 test sequences\n"
     ]
    }
   ],
   "source": [
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad Sequences (samples x time)\n",
      "X_train shape:  (8982, 80)\n",
      "X_test shape:  (2246, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad Sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         3965440   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,097,153\n",
      "Trainable params: 4,097,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/2\n",
      "8982/8982 [==============================] - 34s 4ms/sample - loss: -216.8486 - accuracy: 0.0499 - val_loss: -289.0141 - val_accuracy: 0.0396\n",
      "Epoch 2/2\n",
      "8982/8982 [==============================] - 37s 4ms/sample - loss: -364.2610 - accuracy: 0.0499 - val_loss: -430.5296 - val_accuracy: 0.0396\n"
     ]
    }
   ],
   "source": [
    "alpacas = model.fit(X_train, y_train,\n",
    "          batch_size=64, # Bigger batch sizes result in quicker training but less learning\n",
    "          epochs=2, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sequence Data Question\n",
    "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
    "\n",
    "The pad_sequences method makes sure that all of the sequences are the same length. With this use the max length is set to find the longest sequence and then use a placeholder (like 0) in all of the sequences shorter than the maximum length. It's also possible to use pad_sequences to manually set a max length which will then truncate any sequences longer than the value you choose and make all of the longer sequences shorter. Everything needs to be the same shape so that matrix operations can take place without the program screaming about it.\n",
    "\n",
    "## RNNs versus LSTMs\n",
    "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
    "\n",
    "RNNs and LSTMs are similar in architecture in that they have a long-term memory storage for things that they have seen in previous iterations. For text use they are good at recalling which words have been used a lot compared to those used more rarely. An LSTM is more suitable to a standard RNN, though, because an LSTM has the \"short-term\" part of the memory. An LSTM is great when the order of your data matters, say, in a sentence. In a sequence of data the LSTM has the ability to recall how a point of data fits in with previous data from the same sequence while a standard RNN can't. \n",
    "\n",
    "## RNN / LSTM Use Cases\n",
    "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
    "\n",
    "An LSTM is useful when predicting text; like in the Shakespeare homework project. A standard RNN wouldn't be good at this because it would just put out words and that's nonsense compared to an LSTM learning where the words fit in the sentence. \n",
    "\n",
    "Since LSTMs care about sequence, they are also useful when composing music. For the same reason of wanting words in the sentence to be a particular order we wouldn't just want note vomit to listen to; we want the notes to make sense in a sequence.\n",
    "\n",
    "A standard RNN can be used for speech recognition. It doesn't necessarily need to be concerned with the order that the words are spoken but can still accept the audio data and process it to break down what is being said. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz0LCZd_O4IG"
   },
   "source": [
    "<a id=\"p2\"></a>\n",
    "## Part 2- CNNs\n",
    "\n",
    "### Find the Frog\n",
    "\n",
    "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
    "\n",
    "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "whIqEWR236Af",
    "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread_collection\n",
    "from skimage.transform import resize #This might be a helpful function for you\n",
    "\n",
    "images = imread_collection('./frog_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "EKnnnM8k38sN",
    "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'skimage.io.collection.ImageCollection'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Each of the Images is a Different Size\n",
      "(2137, 1710, 3)\n",
      "(3810, 2856, 3)\n"
     ]
    }
   ],
   "source": [
    "print(type(images))\n",
    "print(type(images[0]), end=\"\\n\\n\")\n",
    "\n",
    "print(\"Each of the Images is a Different Size\")\n",
    "print(images[0].shape)\n",
    "print(images[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2137, 1710, 3)\n",
      "(3810, 2856, 3)\n",
      "(3456, 4608, 3)\n",
      "(2500, 3335, 3)\n",
      "(2000, 3008, 3)\n",
      "(2883, 4319, 3)\n",
      "(4000, 6000, 3)\n",
      "(2642, 3918, 3)\n",
      "(3456, 5184, 3)\n",
      "(2912, 4368, 3)\n",
      "(4928, 3285, 3)\n",
      "(3702, 5397, 3)\n",
      "(1856, 2784, 3)\n",
      "(2592, 3872, 3)\n",
      "(2673, 3382, 3)\n"
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si5YfNqS50QU"
   },
   "source": [
    "Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model. Print out the predictions in any way you see fit. \n",
    "\n",
    "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
    "\n",
    "*Stretch goal* - Check for other things such as fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 2,  2,  2],\n",
       "        [ 2,  2,  2],\n",
       "        [ 2,  2,  2]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 2,  2,  2],\n",
       "        [ 2,  2,  2],\n",
       "        [ 2,  2,  2]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 2,  2,  2],\n",
       "        [ 2,  2,  2],\n",
       "        [ 2,  2,  2]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[15, 16, 11],\n",
       "        [14, 15, 10],\n",
       "        [14, 15, 10],\n",
       "        ...,\n",
       "        [29, 29, 17],\n",
       "        [28, 28, 16],\n",
       "        [28, 28, 16]],\n",
       "\n",
       "       [[14, 15, 10],\n",
       "        [14, 15, 10],\n",
       "        [14, 15, 10],\n",
       "        ...,\n",
       "        [29, 29, 17],\n",
       "        [28, 28, 16],\n",
       "        [28, 28, 16]],\n",
       "\n",
       "       [[13, 14,  9],\n",
       "        [13, 14,  9],\n",
       "        [12, 13,  8],\n",
       "        ...,\n",
       "        [30, 30, 18],\n",
       "        [30, 30, 18],\n",
       "        [29, 29, 17]]], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaT07ddW3nHz"
   },
   "outputs": [],
   "source": [
    "# TODO - your code!\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def resize_img(img):\n",
    "  return resize(img, (224, 224))\n",
    "\n",
    "def process_img_path(img_path):\n",
    "  return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  model = ResNet50(weights='imagenet')\n",
    "  features = model.predict(x)\n",
    "  results = decode_predictions(features, top=3)[0]\n",
    "  print(results)\n",
    "  for entry in results:\n",
    "        if 'frog' in entry[1]:\n",
    "            return entry[2]\n",
    "  return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is my initial, terrible run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n06359193', 'web_site', 0.06232226), ('n03196217', 'digital_clock', 0.053684328), ('n01930112', 'nematode', 0.052816603)]\n",
      "========================================\n",
      "[('n03729826', 'matchstick', 0.0597493), ('n06359193', 'web_site', 0.055891547), ('n03196217', 'digital_clock', 0.047030497)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.0561313), ('n03729826', 'matchstick', 0.051397342), ('n03196217', 'digital_clock', 0.04931623)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.062960126), ('n01930112', 'nematode', 0.05261105), ('n03196217', 'digital_clock', 0.048840858)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.06479917), ('n01930112', 'nematode', 0.04962921), ('n03196217', 'digital_clock', 0.04514363)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.062426906), ('n03196217', 'digital_clock', 0.046223965), ('n01930112', 'nematode', 0.043731824)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.055798694), ('n03196217', 'digital_clock', 0.055427726), ('n03729826', 'matchstick', 0.05286291)]\n",
      "========================================\n",
      "[('n03729826', 'matchstick', 0.051141236), ('n06359193', 'web_site', 0.048578564), ('n03196217', 'digital_clock', 0.04785218)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.07435122), ('n01930112', 'nematode', 0.053619254), ('n03196217', 'digital_clock', 0.04666868)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.063866764), ('n01930112', 'nematode', 0.048485417), ('n03196217', 'digital_clock', 0.04334662)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.064858004), ('n01930112', 'nematode', 0.048752204), ('n03196217', 'digital_clock', 0.044015158)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.059281245), ('n03729826', 'matchstick', 0.050761454), ('n01930112', 'nematode', 0.050517138)]\n",
      "========================================\n",
      "[('n03729826', 'matchstick', 0.05210646), ('n04404412', 'television', 0.038661055), ('n03196217', 'digital_clock', 0.03816635)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.062436413), ('n03196217', 'digital_clock', 0.05423372), ('n01930112', 'nematode', 0.04585019)]\n",
      "========================================\n",
      "[('n06359193', 'web_site', 0.06611588), ('n01930112', 'nematode', 0.0528113), ('n03196217', 'digital_clock', 0.04668361)]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(images)):\n",
    "    print(\"Image: \", i)\n",
    "    img_contains_frog(process_img_path(images[i]))\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an attempt to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_array = [\"frog_images/cristiane-teston-bcnfJvEYm1Y-unsplash.jpg\", \n",
    "                \"frog_images/drew-brown-VBvoy5gofWg-unsplash.jpg\", \n",
    "                \"frog_images/ed-van-duijn-S1zA6AR50X8-unsplash.jpg\", \n",
    "                \"frog_images/elizabeth-explores-JZybccsrB-0-unsplash.jpg\", \n",
    "                \"frog_images/jacky-watt-92W5jPbOj48-unsplash.jpg\", \n",
    "                \"frog_images/jared-evans-VgRnolD7OIw-unsplash.jpg\", \n",
    "                \"frog_images/joel-henry-Rcvf6-n1gc8-unsplash.jpg\", \n",
    "                \"frog_images/marcus-neto-fH_DOdTt-pA-unsplash.jpg\", \n",
    "                \"frog_images/matthew-kosloski-sYkr-M78H6w-unsplash.jpg\", \n",
    "                \"frog_images/mche-lee-j-P8z4EOgyQ-unsplash.jpg\", \n",
    "                \"frog_images/priscilla-du-preez-oWJcgqjFb6I-unsplash.jpg\", \n",
    "                \"frog_images/saturday_sun-_q37Ca0Ll4o-unsplash.jpg\", \n",
    "                \"frog_images/serenity-mitchell-tUDSHkd6rYQ-unsplash.jpg\", \n",
    "                \"frog_images/yanna-zissiadou-SV-aMgliWNs-unsplash.jpg\", \n",
    "                \"frog_images/zdenek-machacek-HYTwWSE5ztw-unsplash (1).jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n07718747', 'artichoke', 0.3059211), ('n02281787', 'lycaenid', 0.23762213), ('n07730033', 'cardoon', 0.18418735)]\n",
      "========================================\n",
      "[('n01641577', 'bullfrog', 0.99152386), ('n01667778', 'terrapin', 0.005188096), ('n02655020', 'puffer', 0.00051200367)]\n",
      "========================================\n",
      "[('n02281787', 'lycaenid', 0.28462553), ('n01641577', 'bullfrog', 0.069064215), ('n01737021', 'water_snake', 0.038429268)]\n",
      "========================================\n",
      "[('n04259630', 'sombrero', 0.4752294), ('n02877765', 'bottlecap', 0.08707738), ('n04409515', 'tennis_ball', 0.065153785)]\n",
      "========================================\n",
      "[('n03991062', 'pot', 0.61137015), ('n11939491', 'daisy', 0.11355704), ('n02840245', 'binder', 0.04898852)]\n",
      "========================================\n",
      "[('n01644373', 'tree_frog', 0.5634745), ('n01641577', 'bullfrog', 0.2976248), ('n01644900', 'tailed_frog', 0.13862132)]\n",
      "========================================\n",
      "[('n01644373', 'tree_frog', 0.9657679), ('n01644900', 'tailed_frog', 0.017379181), ('n02229544', 'cricket', 0.0054068756)]\n",
      "========================================\n",
      "[('n03991062', 'pot', 0.32278636), ('n04409515', 'tennis_ball', 0.30953994), ('n04275548', 'spider_web', 0.13213588)]\n",
      "========================================\n",
      "[('n01641577', 'bullfrog', 0.7582518), ('n02398521', 'hippopotamus', 0.17951876), ('n01644900', 'tailed_frog', 0.030233152)]\n",
      "========================================\n",
      "[('n03938244', 'pillow', 0.27643475), ('n04033995', 'quilt', 0.16066167), ('n01910747', 'jellyfish', 0.10251855)]\n",
      "========================================\n",
      "[('n02363005', 'beaver', 0.11364403), ('n01641577', 'bullfrog', 0.07960135), ('n09428293', 'seashore', 0.05411975)]\n",
      "========================================\n",
      "[('n04326547', 'stone_wall', 0.23979749), ('n04435653', 'tile_roof', 0.12859939), ('n01641577', 'bullfrog', 0.0843225)]\n",
      "========================================\n",
      "[('n11939491', 'daisy', 0.52724546), ('n02280649', 'cabbage_butterfly', 0.12850808), ('n01737021', 'water_snake', 0.089858316)]\n",
      "========================================\n",
      "[('n01944390', 'snail', 0.698253), ('n02281787', 'lycaenid', 0.083721936), ('n01737021', 'water_snake', 0.04630219)]\n",
      "========================================\n",
      "[('n01644373', 'tree_frog', 0.9716323), ('n01644900', 'tailed_frog', 0.0062739216), ('n01693334', 'green_lizard', 0.0049903234)]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for img in images_array:\n",
    "    img_contains_frog(process_img_path(img))\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK! That's more like it. There are definitely frogs in those predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEuhvSu7O5Rf"
   },
   "source": [
    "<a id=\"p3\"></a>\n",
    "## Part 3 - Autoencoders\n",
    "\n",
    "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
    "\n",
    "__*Your Answer:*__ Apparently autoencoders are quite useful when you want to remove noise from some data. If you have a messy image you can pass it through a trained autoencoder and it will clean up the image ready for predictions that the autoencoder can then make. For example, you want to check an image for a number like in the MNIST dataset that we used this week. The autoencoder can take in somewhat sloppily written digits or images that at not very crisp, compress it down, then decode it and make a prediction about which digit it is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "626zYgjkO7Vq"
   },
   "source": [
    "<a id=\"p4\"></a>\n",
    "## Part 4 - More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__lDWfcUO8oo"
   },
   "source": [
    "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
    "\n",
    "- What do you consider your strongest area, as a Data Scientist?\n",
    "\n",
    "Honestly, I'm not sure. I recognize in myself a need to improve as there are many things I do not understand, yet. I want to improve in these areas, too. But the field is so exapansive that it's hard to decide where to focus my efforts. \n",
    "\n",
    "- What area of Data Science would you most like to learn more about, and why?\n",
    "\n",
    "Neural networks and artifical intelligence is the area that is most appealing to me right now because it seems so mysterious. I haven't spent any time in reinforcement learning but I have been captivated by seeing advances in how AI is applied to games like Go and Starcraft 2. I enjoy seeing the machine learn different strategies that makes people step back and rethink what they once thought about the game.\n",
    "\n",
    "- Where do you think Data Science will be in 5 years?\n",
    "\n",
    "In a very similar boat to the one it is currently in; but maybe bigger. There's so much data being generated and it would be nice for there to be ways to understand that data. The field itself will likely continue growing rapidly and advances in AI will help get the job done. \n",
    "\n",
    "- What are the threats posed by AI to our society?\n",
    "\n",
    "The biggest threats to our society from AI in my mind are automation and privacy concerns. As AI becomes more advacned it will make human implementation of some tasks just unnecessary and even too costly so those jobs will go to computers. This will leave people without jobs and I'm not sure our soceity is ready to provide for those people and help train them into another job. Privacy is also a concern as cameras and recorders are ubiquitous and it's not unimaginable that someone could take advantage of those and track a little too much information.\n",
    "\n",
    "- How do you think we can counteract those threats? \n",
    "\n",
    "My favorite idea about dealing with automation is a universal basic income. It makes sense that if we can get the job done without people then we should be able to still provide the needs for those people. After all, decades ago the ideal was to use computers to do the job so that we, as a society, could spend more time improving ourselves as people. To counter the privacy concerns it might take laws to do so or maybe even counter AI programs to look for those taking advantage of others.\n",
    "\n",
    "- Do you think achieving General Artifical Intelligence is ever possible?\n",
    "\n",
    "Absolutely. Not soon, though. I don't see a definite reason why a program couldn't be written to take in data, process it, and adapt that data into new areas. This is precisely what we do as humans. Granted, we have many many generations of evolution working for us in this regard but I think we could get to the point where AI can abstract ideas from one case and use them in a different one.\n",
    "\n",
    "A few sentences per answer is fine - only elaborate if time allows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hoqe3mM_Mtc"
   },
   "source": [
    "## Congratulations! \n",
    "\n",
    "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Neal\\\\Documents\\\\Lambda_Classnotes\\\\Unit_4_Sprint_3_Challenge'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - your code!\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "# def resize_img(img):\n",
    "#   return resize(img, (224, 224))\n",
    "\n",
    "def process_img_path(img_path):\n",
    "  return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  model = ResNet50(weights='imagenet')\n",
    "  features = model.predict(x)\n",
    "  results = decode_predictions(features, top=5)[0]\n",
    "  print(results)\n",
    "  prob = 0\n",
    "  for entry in results:\n",
    "    if 'frog' in entry[1]:\n",
    "      prob += entry[2]\n",
    "  if prob == 0:\n",
    "    print(\"A frog was not predicted in the top five results.\")\n",
    "  else:\n",
    "    print(f\"The program predicts a {prob:.2f}% chance of the image containing a frog.\")\n",
    "#  return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n01641577', 'bullfrog', 0.99152386), ('n01667778', 'terrapin', 0.005188096), ('n02655020', 'puffer', 0.00051200367), ('n02514041', 'barracouta', 0.00038378476), ('n03388043', 'fountain', 0.0002847035)]\n",
      "The program predicts a 0.99% chance of the image containing a frog.\n"
     ]
    }
   ],
   "source": [
    "img_contains_frog(process_img_path('frog_images/drew-brown-VBvoy5gofWg-unsplash.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cristiane-teston-bcnfJvEYm1Y-unsplash.jpg',\n",
       " 'drew-brown-VBvoy5gofWg-unsplash.jpg',\n",
       " 'ed-van-duijn-S1zA6AR50X8-unsplash.jpg',\n",
       " 'elizabeth-explores-JZybccsrB-0-unsplash.jpg',\n",
       " 'jacky-watt-92W5jPbOj48-unsplash.jpg',\n",
       " 'jared-evans-VgRnolD7OIw-unsplash.jpg',\n",
       " 'joel-henry-Rcvf6-n1gc8-unsplash.jpg',\n",
       " 'marcus-neto-fH_DOdTt-pA-unsplash.jpg',\n",
       " 'matthew-kosloski-sYkr-M78H6w-unsplash.jpg',\n",
       " 'mche-lee-j-P8z4EOgyQ-unsplash.jpg',\n",
       " 'priscilla-du-preez-oWJcgqjFb6I-unsplash.jpg',\n",
       " 'saturday_sun-_q37Ca0Ll4o-unsplash.jpg',\n",
       " 'serenity-mitchell-tUDSHkd6rYQ-unsplash.jpg',\n",
       " 'yanna-zissiadou-SV-aMgliWNs-unsplash.jpg',\n",
       " 'zdenek-machacek-HYTwWSE5ztw-unsplash (1).jpg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "path = \"./frog_images/\"\n",
    "\n",
    "images = [f for f in listdir(path)]\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frog_images/cristiane-teston-bcnfJvEYm1Y-unsplash.jpg',\n",
       " 'frog_images/drew-brown-VBvoy5gofWg-unsplash.jpg',\n",
       " 'frog_images/ed-van-duijn-S1zA6AR50X8-unsplash.jpg',\n",
       " 'frog_images/elizabeth-explores-JZybccsrB-0-unsplash.jpg',\n",
       " 'frog_images/jacky-watt-92W5jPbOj48-unsplash.jpg',\n",
       " 'frog_images/jared-evans-VgRnolD7OIw-unsplash.jpg',\n",
       " 'frog_images/joel-henry-Rcvf6-n1gc8-unsplash.jpg',\n",
       " 'frog_images/marcus-neto-fH_DOdTt-pA-unsplash.jpg',\n",
       " 'frog_images/matthew-kosloski-sYkr-M78H6w-unsplash.jpg',\n",
       " 'frog_images/mche-lee-j-P8z4EOgyQ-unsplash.jpg',\n",
       " 'frog_images/priscilla-du-preez-oWJcgqjFb6I-unsplash.jpg',\n",
       " 'frog_images/saturday_sun-_q37Ca0Ll4o-unsplash.jpg',\n",
       " 'frog_images/serenity-mitchell-tUDSHkd6rYQ-unsplash.jpg',\n",
       " 'frog_images/yanna-zissiadou-SV-aMgliWNs-unsplash.jpg',\n",
       " 'frog_images/zdenek-machacek-HYTwWSE5ztw-unsplash (1).jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(images)):\n",
    "    images[i] = 'frog_images/' + images[i]\n",
    "    \n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n07718747', 'artichoke', 0.3059211), ('n02281787', 'lycaenid', 0.23762213), ('n07730033', 'cardoon', 0.18418735), ('n11939491', 'daisy', 0.047543373), ('n02280649', 'cabbage_butterfly', 0.03801479)]\n",
      "A frog was not predicted in the top five results.\n",
      "======================================================================\n",
      "[('n01641577', 'bullfrog', 0.99152386), ('n01667778', 'terrapin', 0.005188096), ('n02655020', 'puffer', 0.00051200367), ('n02514041', 'barracouta', 0.00038378476), ('n03388043', 'fountain', 0.0002847035)]\n",
      "The program predicts a 0.99% chance of the image containing a frog.\n",
      "======================================================================\n",
      "[('n02281787', 'lycaenid', 0.28462553), ('n01641577', 'bullfrog', 0.069064215), ('n01737021', 'water_snake', 0.038429268), ('n03314780', 'face_powder', 0.037996422), ('n01644900', 'tailed_frog', 0.03340858)]\n",
      "The program predicts a 0.10% chance of the image containing a frog.\n",
      "======================================================================\n",
      "[('n04259630', 'sombrero', 0.4752294), ('n02877765', 'bottlecap', 0.08707738), ('n04409515', 'tennis_ball', 0.065153785), ('n03983396', 'pop_bottle', 0.045623694), ('n03249569', 'drum', 0.045290284)]\n",
      "A frog was not predicted in the top five results.\n",
      "======================================================================\n",
      "[('n03991062', 'pot', 0.61137015), ('n11939491', 'daisy', 0.11355704), ('n02840245', 'binder', 0.04898852), ('n03950228', 'pitcher', 0.04516104), ('n04476259', 'tray', 0.029595312)]\n",
      "A frog was not predicted in the top five results.\n",
      "======================================================================\n",
      "[('n01644373', 'tree_frog', 0.5634745), ('n01641577', 'bullfrog', 0.2976248), ('n01644900', 'tailed_frog', 0.13862132), ('n01687978', 'agama', 5.5917953e-05), ('n01629819', 'European_fire_salamander', 4.4921184e-05)]\n",
      "The program predicts a 1.00% chance of the image containing a frog.\n",
      "======================================================================\n",
      "[('n01644373', 'tree_frog', 0.9657679), ('n01644900', 'tailed_frog', 0.017379181), ('n02229544', 'cricket', 0.0054068756), ('n02226429', 'grasshopper', 0.004393143), ('n01682714', 'American_chameleon', 0.004190576)]\n",
      "The program predicts a 0.98% chance of the image containing a frog.\n",
      "======================================================================\n",
      "[('n03991062', 'pot', 0.32278636), ('n04409515', 'tennis_ball', 0.30953994), ('n04275548', 'spider_web', 0.13213588), ('n02877765', 'bottlecap', 0.03831858), ('n01641577', 'bullfrog', 0.016123218)]\n",
      "The program predicts a 0.02% chance of the image containing a frog.\n",
      "======================================================================\n",
      "[('n01641577', 'bullfrog', 0.7582518), ('n02398521', 'hippopotamus', 0.17951876), ('n01644900', 'tailed_frog', 0.030233152), ('n01698640', 'American_alligator', 0.009161242), ('n01986214', 'hermit_crab', 0.006538247)]\n",
      "The program predicts a 0.79% chance of the image containing a frog.\n",
      "======================================================================\n",
      "[('n03938244', 'pillow', 0.27643475), ('n04033995', 'quilt', 0.16066167), ('n01910747', 'jellyfish', 0.10251855), ('n02834397', 'bib', 0.07038012), ('n11939491', 'daisy', 0.06103836)]\n",
      "A frog was not predicted in the top five results.\n",
      "======================================================================\n",
      "[('n02363005', 'beaver', 0.11364403), ('n01641577', 'bullfrog', 0.07960135), ('n09428293', 'seashore', 0.05411975), ('n09256479', 'coral_reef', 0.04665924), ('n01737021', 'water_snake', 0.041625075)]\n",
      "The program predicts a 0.08% chance of the image containing a frog.\n",
      "======================================================================\n",
      "[('n04326547', 'stone_wall', 0.23979749), ('n04435653', 'tile_roof', 0.12859939), ('n01641577', 'bullfrog', 0.0843225), ('n01737021', 'water_snake', 0.074981466), ('n02172182', 'dung_beetle', 0.060559165)]\n",
      "The program predicts a 0.08% chance of the image containing a frog.\n",
      "======================================================================\n",
      "[('n11939491', 'daisy', 0.52724546), ('n02280649', 'cabbage_butterfly', 0.12850808), ('n01737021', 'water_snake', 0.089858316), ('n03991062', 'pot', 0.042010244), ('n02009229', 'little_blue_heron', 0.041271426)]\n",
      "A frog was not predicted in the top five results.\n",
      "======================================================================\n",
      "[('n01944390', 'snail', 0.698253), ('n02281787', 'lycaenid', 0.083721936), ('n01737021', 'water_snake', 0.04630219), ('n11939491', 'daisy', 0.042628653), ('n02190166', 'fly', 0.01593819)]\n",
      "A frog was not predicted in the top five results.\n",
      "======================================================================\n",
      "[('n01644373', 'tree_frog', 0.9716323), ('n01644900', 'tailed_frog', 0.0062739216), ('n01693334', 'green_lizard', 0.0049903234), ('n02259212', 'leafhopper', 0.0030559131), ('n01641577', 'bullfrog', 0.0023793415)]\n",
      "The program predicts a 0.98% chance of the image containing a frog.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    img_contains_frog(process_img_path(img))\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['frog_images/cristiane-teston-bcnfJvEYm1Y-unsplash.jpg',\n",
       " 'frog_images/drew-brown-VBvoy5gofWg-unsplash.jpg',\n",
       " 'frog_images/ed-van-duijn-S1zA6AR50X8-unsplash.jpg',\n",
       " 'frog_images/elizabeth-explores-JZybccsrB-0-unsplash.jpg',\n",
       " 'frog_images/jacky-watt-92W5jPbOj48-unsplash.jpg',\n",
       " 'frog_images/jared-evans-VgRnolD7OIw-unsplash.jpg',\n",
       " 'frog_images/joel-henry-Rcvf6-n1gc8-unsplash.jpg',\n",
       " 'frog_images/marcus-neto-fH_DOdTt-pA-unsplash.jpg',\n",
       " 'frog_images/matthew-kosloski-sYkr-M78H6w-unsplash.jpg',\n",
       " 'frog_images/mche-lee-j-P8z4EOgyQ-unsplash.jpg',\n",
       " 'frog_images/priscilla-du-preez-oWJcgqjFb6I-unsplash.jpg',\n",
       " 'frog_images/saturday_sun-_q37Ca0Ll4o-unsplash.jpg',\n",
       " 'frog_images/serenity-mitchell-tUDSHkd6rYQ-unsplash.jpg',\n",
       " 'frog_images/yanna-zissiadou-SV-aMgliWNs-unsplash.jpg',\n",
       " 'frog_images/zdenek-machacek-HYTwWSE5ztw-unsplash (1).jpg']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "path = \"./frog_images/\"\n",
    "\n",
    "images = [('frog_images/' + f) for f in listdir(path)]\n",
    "\n",
    "print(len(images))\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['frog_images/cristiane-teston-bcnfJvEYm1Y-unsplash.jpg',\n",
       " 'frog_images/drew-brown-VBvoy5gofWg-unsplash.jpg',\n",
       " 'frog_images/ed-van-duijn-S1zA6AR50X8-unsplash.jpg',\n",
       " 'frog_images/elizabeth-explores-JZybccsrB-0-unsplash.jpg',\n",
       " 'frog_images/jacky-watt-92W5jPbOj48-unsplash.jpg',\n",
       " 'frog_images/jared-evans-VgRnolD7OIw-unsplash.jpg',\n",
       " 'frog_images/joel-henry-Rcvf6-n1gc8-unsplash.jpg',\n",
       " 'frog_images/marcus-neto-fH_DOdTt-pA-unsplash.jpg',\n",
       " 'frog_images/matthew-kosloski-sYkr-M78H6w-unsplash.jpg',\n",
       " 'frog_images/mche-lee-j-P8z4EOgyQ-unsplash.jpg',\n",
       " 'frog_images/priscilla-du-preez-oWJcgqjFb6I-unsplash.jpg',\n",
       " 'frog_images/saturday_sun-_q37Ca0Ll4o-unsplash.jpg',\n",
       " 'frog_images/serenity-mitchell-tUDSHkd6rYQ-unsplash.jpg',\n",
       " 'frog_images/yanna-zissiadou-SV-aMgliWNs-unsplash.jpg',\n",
       " 'frog_images/zdenek-machacek-HYTwWSE5ztw-unsplash (1).jpg']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "images = [('frog_images/' + f) for f in listdir(\"./frog_images/\")]\n",
    "\n",
    "print(len(images))\n",
    "images"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "u4-s3-dnn"
  },
  "kernelspec": {
   "display_name": "U4-S3-DL (Python3)",
   "language": "python",
   "name": "u4-s2-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
